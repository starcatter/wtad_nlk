{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('why arent you going because i dont want to', '[start] dlaczego nie idziesz bo nie chce [end]')\n",
      "('i dont have an answer', '[start] nie posiadam odpowiedzi [end]')\n",
      "('please remember to mail the letters', '[start] pamietaj aby wyslac te listy [end]')\n",
      "('come here', '[start] chodz tu [end]')\n",
      "('im afraid i cant afford to buy a new car', '[start] obawiam sie ze nie stac mnie na zakup nowego samochodu [end]')\n",
      "41666 total pairs\n",
      "29168 training pairs\n",
      "6249 validation pairs\n",
      "6249 test pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 00:16:06.090350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.116141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.116334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.116923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-21 00:16:06.121475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.121690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.121824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.469469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.469656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.469801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-21 00:16:06.469925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5209 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# assemble text data for english->polish translation\n",
    "translator.prepare_text_zip(\"in/pol-eng.zip\",\"pol.txt\",\"lang/eng-pol\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above will clean the text input, split the data into training/verification/test sets, and setup and fit vectorizers for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do ktorego klubu nalezysz', '[start] what club do you belong to [end]')\n",
      "('juz prawie czas spac', '[start] its almost bedtime [end]')\n",
      "('niebo jest zachmurzone', '[start] its cloudy [end]')\n",
      "('tom prawie powiedzial mary ze ja kocha', '[start] tom almost told mary that he loved her [end]')\n",
      "('nie umiem obslugiwac tej maszyny', '[start] i cant figure out how to operate this machine [end]')\n",
      "41666 total pairs\n",
      "29168 training pairs\n",
      "6249 validation pairs\n",
      "6249 test pairs\n"
     ]
    }
   ],
   "source": [
    "# text data for reverse translation\n",
    "translator.prepare_text_zip(\"in/pol-eng.zip\",\"pol.txt\",\"lang/pol-eng\", flip_translation=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (256, 16)\n",
      "inputs[\"decoder_inputs\"].shape: (256, 16)\n",
      "targets.shape: (256, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 00:16:11.495063: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " token_and_position_embedding (  (None, None, 256)   12804096    ['encoder_inputs[0][0]']         \n",
      " TokenAndPositionEmbedding)                                                                       \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " TransformerEncoder (Transforme  (None, None, 256)   785652      ['token_and_position_embedding[0]\n",
      " rEncoder)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 50000)  29336656    ['decoder_inputs[0][0]',         \n",
      "                                                                  'TransformerEncoder[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 42,926,404\n",
      "Trainable params: 42,926,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 00:16:14.544796: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 24s 186ms/step - loss: 3.0703 - accuracy: 0.6742 - val_loss: 2.3450 - val_accuracy: 0.7009\n",
      "Epoch 2/4\n",
      "114/114 [==============================] - 21s 184ms/step - loss: 2.2215 - accuracy: 0.7070 - val_loss: 2.2010 - val_accuracy: 0.7155\n",
      "Epoch 3/4\n",
      "114/114 [==============================] - 21s 186ms/step - loss: 1.9522 - accuracy: 0.7359 - val_loss: 2.0539 - val_accuracy: 0.7302\n",
      "Epoch 4/4\n",
      "114/114 [==============================] - 21s 188ms/step - loss: 1.7388 - accuracy: 0.7550 - val_loss: 1.8419 - val_accuracy: 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 68). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/eng-pol/transformer.ts/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/eng-pol/transformer.ts/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 916 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f89a413f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 916 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f89a413f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "114/114 [==============================] - 23s 190ms/step - loss: 1.7574 - accuracy: 0.7582 - val_loss: 1.7066 - val_accuracy: 0.7725\n",
      "Epoch 2/4\n",
      "114/114 [==============================] - 22s 190ms/step - loss: 1.4890 - accuracy: 0.7805 - val_loss: 1.6461 - val_accuracy: 0.7766\n",
      "Epoch 3/4\n",
      "114/114 [==============================] - 22s 192ms/step - loss: 1.3495 - accuracy: 0.7920 - val_loss: 1.5748 - val_accuracy: 0.7805\n",
      "Epoch 4/4\n",
      "114/114 [==============================] - 22s 192ms/step - loss: 1.2253 - accuracy: 0.8024 - val_loss: 1.5552 - val_accuracy: 0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, restored_function_body, restored_function_body, multi_head_attention_layer_call_fn while saving (showing 5 of 68). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/eng-pol/transformer.ts/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/eng-pol/transformer.ts/assets\n"
     ]
    }
   ],
   "source": [
    "# create and pre-train translation model\n",
    "translator.create_translator(\"lang/eng-pol\", \"trans/eng-pol\")\n",
    "\n",
    "# train the model some more\n",
    "translator.train_model(\"lang/eng-pol\", \"trans/eng-pol\", 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 917 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f89c44e8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 917 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f89c44e8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in:[Hello world] -> out:[ prosze ]\n",
      "in:[Good morning] -> out:[ prosze rano ]\n"
     ]
    }
   ],
   "source": [
    "# translate some phrases\n",
    "translator.translate_sequences(\"lang/eng-pol\", \"trans/eng-pol\", [\"Hello world\", \"Good morning\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in:[theyre just lazy] -> out:[ oni prostu jeszcze ]\n",
      "in:[she wants me to go with her] -> out:[ ona chce do niej z nia ]\n",
      "in:[clearly you are mistaken] -> out:[ to jest sie ]\n",
      "in:[make another appointment at the front desk] -> out:[ zrob na jedno przed ]\n",
      "in:[he still has a white vest] -> out:[ on bardzo ma za ]\n",
      "in:[we have a problem tom] -> out:[ mamy problem ]\n",
      "in:[he made it for his sister] -> out:[ zrobil to dla siostra ]\n",
      "in:[i am from shizuoka] -> out:[ jestem z gory ]\n",
      "in:[my thirteen year old girl loves to watch romance movies] -> out:[ moja dwa dwa dwa lubi lubie ]\n",
      "in:[ill join you in a moment] -> out:[ bede na ciebie chwile ]\n"
     ]
    }
   ],
   "source": [
    "# translate some sequences from file\n",
    "with open(\"lang/eng-pol/test_texts.txt\", \"rt\") as file_in:\n",
    "\tlines = file_in.readlines()\n",
    "\ttranslator.translate_sequences(\"lang/eng-pol\", \"trans/eng-pol\", random.sample(lines, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (256, 16)\n",
      "inputs[\"decoder_inputs\"].shape: (256, 16)\n",
      "targets.shape: (256, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 00:24:52.458349: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " token_and_position_embedding_2  (None, None, 256)   12804096    ['encoder_inputs[0][0]']         \n",
      "  (TokenAndPositionEmbedding)                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " TransformerEncoder (Transforme  (None, None, 256)   785652      ['token_and_position_embedding_2[\n",
      " rEncoder)                                                       0][0]']                          \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, None, 50000)  29336656    ['decoder_inputs[0][0]',         \n",
      "                                                                  'TransformerEncoder[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 42,926,404\n",
      "Trainable params: 42,926,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "114/114 [==============================] - 26s 211ms/step - loss: 3.0419 - accuracy: 0.6158 - val_loss: 2.4413 - val_accuracy: 0.6347\n",
      "Epoch 2/8\n",
      "114/114 [==============================] - 24s 211ms/step - loss: 2.1869 - accuracy: 0.6526 - val_loss: 2.0656 - val_accuracy: 0.6771\n",
      "Epoch 3/8\n",
      "114/114 [==============================] - 23s 204ms/step - loss: 1.8827 - accuracy: 0.6915 - val_loss: 1.7988 - val_accuracy: 0.7113\n",
      "Epoch 4/8\n",
      "114/114 [==============================] - 22s 190ms/step - loss: 1.6159 - accuracy: 0.7259 - val_loss: 1.6280 - val_accuracy: 0.7353\n",
      "Epoch 5/8\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.4098 - accuracy: 0.7508 - val_loss: 1.5824 - val_accuracy: 0.7417\n",
      "Epoch 6/8\n",
      "114/114 [==============================] - 26s 229ms/step - loss: 1.2378 - accuracy: 0.7717 - val_loss: 1.5103 - val_accuracy: 0.7535\n",
      "Epoch 7/8\n",
      "114/114 [==============================] - 24s 209ms/step - loss: 1.0903 - accuracy: 0.7905 - val_loss: 1.4376 - val_accuracy: 0.7605\n",
      "Epoch 8/8\n",
      "114/114 [==============================] - 26s 231ms/step - loss: 0.9677 - accuracy: 0.8056 - val_loss: 1.3916 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_2_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses, position_embedding_2_layer_call_fn, position_embedding_2_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 68). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/pol-eng/transformer.ts/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trans/pol-eng/transformer.ts/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in:[nie musisz krzyczec] -> out:[ you dont have to keep ]\n",
      "in:[nikt nie wie jak sie czuje] -> out:[ nobody one knows how like ]\n",
      "in:[zgubilismy sie w lesie] -> out:[ we lost in the woods ]\n",
      "in:[sadze ze bylam zbyt zajeta by zauwazyc ze tom mial problemy] -> out:[ i think i was very very tom would that he had a native ]\n",
      "in:[tom wszedl niosac szesciopak piwa] -> out:[ tom fell the gate were beer ]\n",
      "in:[tom nigdy nie bedzie cie kochal] -> out:[ tom would never be you ]\n",
      "in:[jestesmy kreatywni] -> out:[ were a bit ]\n",
      "in:[nie chce cie] -> out:[ i dont want you ]\n",
      "in:[czy moge uzyc twojego olowka] -> out:[ may i use your your ]\n",
      "in:[moja siostra jest piekna] -> out:[ my sister is beautiful ]\n"
     ]
    }
   ],
   "source": [
    "# create another translator\n",
    "translator.create_translator(\"lang/pol-eng\", \"trans/pol-eng\", epochs=8)\n",
    "\n",
    "# see how it works\n",
    "with open(\"lang/pol-eng/test_texts.txt\", \"rt\") as file_in:\n",
    "\tlines = file_in.readlines()\n",
    "\ttranslator.translate_sequences(\"lang/pol-eng\", \"trans/pol-eng\", random.sample(lines, 10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}